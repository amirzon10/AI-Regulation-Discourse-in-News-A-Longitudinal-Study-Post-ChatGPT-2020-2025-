{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62f8ddcd",
   "metadata": {},
   "source": [
    "# Language Translation for Media Cloud dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f211aa69",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This notebook processes the MediaCloud dataset (2020-2025) by translating non-English article titles to English while preserving original English titles. The pipeline implements a robust data preprocessing and translation workflow designed for large-scale multilingual text processing.\n",
    "\n",
    "- **Chunked Processing**: Handles large datasets efficiently in configurable chunks (default: 1000 rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dbbb9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from deep_translator import GoogleTranslator\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "380d8c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "indexed_date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "language",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "media_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "media_url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "publish_date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "url",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "26f9de20-24c1-4ec6-95d0-13478580fdcd",
       "rows": [
        [
         "0",
         "1dc171e7750c319dc4a7b4ca87c8a6f5587c0e9481f12970f30a427f0f7efb4d",
         "2025-11-03 00:22:19.404264+00:00",
         "en",
         "techcrunch.com",
         "techcrunch.com",
         "2025-11-02",
         "Google pulls Gemma from AI Studio after Senator Blackburn accuses model of defamation",
         "https://techcrunch.com/2025/11/02/google-pulls-gemma-from-ai-studio-after-senator-blackburn-accuses-model-of-defamation/"
        ],
        [
         "1",
         "e6a47f0c7b6de768d799e603b5797ca432f9af6903de7bea1dd97d2b08228311",
         "2025-11-02 23:17:22.553191+00:00",
         "en",
         "livemint.com",
         "livemint.com",
         "2025-11-02",
         "Here's why India’s AI content draft rules miss the mark on consumer protection",
         "https://www.livemint.com/opinion/online-views/ai-regulation-india-draft-rules-consumer-protection-act-2019-legislation-misuse-customer-service-chatbot-cost-saving-11761906038586.html"
        ],
        [
         "2",
         "8061d40a29f0fcf33e6906573a72389a4c0a0cc136522cf1c04e3d214c6f4119",
         "2025-11-02 21:51:34.827292+00:00",
         "en",
         "apnews.com",
         "apnews.com",
         "2025-11-02",
         "Who is Zico Kolter? A professor leads OpenAI safety panel with power to halt unsafe AI releases",
         "https://apnews.com/article/openai-safety-chatgpt-zico-kolter-3f1522b08268ec2e87d9932dc42b4d80"
        ],
        [
         "3",
         "d411e1a49c87e2e710c054d514f58beebcfa2f275107d8ac2509d7af1d011cf3",
         "2025-11-02 20:26:57.088674+00:00",
         "es",
         "infolibre.es",
         "infolibre.es",
         "2025-11-02",
         "ChatGPT no es un psicólogo, pero cambiará su lenguaje para alertar a usuarios con problemas de salud mental",
         "https://www.infolibre.es/politica/chatgpt-rectifica-lenguaje-salud-mental-prestara-ayuda-modificara-conversaciones-evitar-problemas-usuarios_1_2090482.html"
        ],
        [
         "4",
         "c8ce06691fdf797a875be76c82efb7b0fab0d3d62a795ced4993b601f6edf09c",
         "2025-11-02 20:17:51.246694+00:00",
         "en",
         "thestar.com",
         "thestar.com",
         "2025-11-02",
         "Like maple syrup and hockey, AI must become a part of our national identity",
         "https://www.thestar.com/business/opinion/like-maple-syrup-and-hockey-ai-must-become-a-part-of-our-national-identity/article_1faa24ab-0fe1-4db4-b3c0-941179069507.html"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>indexed_date</th>\n",
       "      <th>language</th>\n",
       "      <th>media_name</th>\n",
       "      <th>media_url</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1dc171e7750c319dc4a7b4ca87c8a6f5587c0e9481f129...</td>\n",
       "      <td>2025-11-03 00:22:19.404264+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>techcrunch.com</td>\n",
       "      <td>techcrunch.com</td>\n",
       "      <td>2025-11-02</td>\n",
       "      <td>Google pulls Gemma from AI Studio after Senato...</td>\n",
       "      <td>https://techcrunch.com/2025/11/02/google-pulls...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e6a47f0c7b6de768d799e603b5797ca432f9af6903de7b...</td>\n",
       "      <td>2025-11-02 23:17:22.553191+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>livemint.com</td>\n",
       "      <td>livemint.com</td>\n",
       "      <td>2025-11-02</td>\n",
       "      <td>Here's why India’s AI content draft rules miss...</td>\n",
       "      <td>https://www.livemint.com/opinion/online-views/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8061d40a29f0fcf33e6906573a72389a4c0a0cc136522c...</td>\n",
       "      <td>2025-11-02 21:51:34.827292+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>apnews.com</td>\n",
       "      <td>apnews.com</td>\n",
       "      <td>2025-11-02</td>\n",
       "      <td>Who is Zico Kolter? A professor leads OpenAI s...</td>\n",
       "      <td>https://apnews.com/article/openai-safety-chatg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d411e1a49c87e2e710c054d514f58beebcfa2f275107d8...</td>\n",
       "      <td>2025-11-02 20:26:57.088674+00:00</td>\n",
       "      <td>es</td>\n",
       "      <td>infolibre.es</td>\n",
       "      <td>infolibre.es</td>\n",
       "      <td>2025-11-02</td>\n",
       "      <td>ChatGPT no es un psicólogo, pero cambiará su l...</td>\n",
       "      <td>https://www.infolibre.es/politica/chatgpt-rect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c8ce06691fdf797a875be76c82efb7b0fab0d3d62a795c...</td>\n",
       "      <td>2025-11-02 20:17:51.246694+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>thestar.com</td>\n",
       "      <td>thestar.com</td>\n",
       "      <td>2025-11-02</td>\n",
       "      <td>Like maple syrup and hockey, AI must become a ...</td>\n",
       "      <td>https://www.thestar.com/business/opinion/like-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  \\\n",
       "0  1dc171e7750c319dc4a7b4ca87c8a6f5587c0e9481f129...   \n",
       "1  e6a47f0c7b6de768d799e603b5797ca432f9af6903de7b...   \n",
       "2  8061d40a29f0fcf33e6906573a72389a4c0a0cc136522c...   \n",
       "3  d411e1a49c87e2e710c054d514f58beebcfa2f275107d8...   \n",
       "4  c8ce06691fdf797a875be76c82efb7b0fab0d3d62a795c...   \n",
       "\n",
       "                       indexed_date language      media_name       media_url  \\\n",
       "0  2025-11-03 00:22:19.404264+00:00       en  techcrunch.com  techcrunch.com   \n",
       "1  2025-11-02 23:17:22.553191+00:00       en    livemint.com    livemint.com   \n",
       "2  2025-11-02 21:51:34.827292+00:00       en      apnews.com      apnews.com   \n",
       "3  2025-11-02 20:26:57.088674+00:00       es    infolibre.es    infolibre.es   \n",
       "4  2025-11-02 20:17:51.246694+00:00       en     thestar.com     thestar.com   \n",
       "\n",
       "  publish_date                                              title  \\\n",
       "0   2025-11-02  Google pulls Gemma from AI Studio after Senato...   \n",
       "1   2025-11-02  Here's why India’s AI content draft rules miss...   \n",
       "2   2025-11-02  Who is Zico Kolter? A professor leads OpenAI s...   \n",
       "3   2025-11-02  ChatGPT no es un psicólogo, pero cambiará su l...   \n",
       "4   2025-11-02  Like maple syrup and hockey, AI must become a ...   \n",
       "\n",
       "                                                 url  \n",
       "0  https://techcrunch.com/2025/11/02/google-pulls...  \n",
       "1  https://www.livemint.com/opinion/online-views/...  \n",
       "2  https://apnews.com/article/openai-safety-chatg...  \n",
       "3  https://www.infolibre.es/politica/chatgpt-rect...  \n",
       "4  https://www.thestar.com/business/opinion/like-...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/mediacloud-2020-2025-dataset.csv\", encoding='utf-8')\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c65bd50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique languages: 48\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of unique languages:\", df['language'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daf9227c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['es', 'ja', 'de', 'pl', 'fr', 'ro', 'it', 'hr', 'fa', 'id', 'hi', 'zh', 'no', 'nl', 'hu', 'uk', 'ru', 'pt', 'sv', 'sq', 'bg', 'la', 'sr', 'se', 'ca', 'tr', 'he', 'cs', 'sw', 'el', 'fi', 'gl', 'th', 'mt', 'ko', 'ml', 'nb', 'is', 'ta', 'sk', 'nn', 'tl', 'ar', 'ka', 'ur', 'mk', 'az']\n"
     ]
    }
   ],
   "source": [
    "# Get unique language codes from the DataFrame (numpy array)\n",
    "languages = df[\"language\"].unique()\n",
    "\n",
    "# Create a list of language codes excluding English ('en')\n",
    "non_english_languages = [lang for lang in languages if lang != \"en\"]\n",
    "print(non_english_languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55bb6b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supported languages dictionary sample: {'afrikaans': 'af', 'albanian': 'sq', 'amharic': 'am', 'arabic': 'ar', 'armenian': 'hy', 'assamese': 'as', 'aymara': 'ay', 'azerbaijani': 'az', 'bambara': 'bm', 'basque': 'eu'}\n",
      "Supported language codes: 133 languages\n",
      "Note: 'zh' detected in dataset, will map to 'zh-CN' for translation\n",
      "Non-English languages from dataset: 47\n",
      "Supported languages for translation: 43\n",
      "Supported languages: {'ko', 'ro', 'id', 'ar', 'fa', 'sk', 'zh-CN', 'ca', 'la', 'ka', 'sv', 'cs', 'hu', 'el', 'hi', 'sq', 'az', 'es', 'th', 'nl', 'gl', 'uk', 'fi', 'fr', 'bg', 'tr', 'sw', 'no', 'ru', 'ta', 'ml', 'it', 'de', 'sr', 'mt', 'mk', 'pt', 'tl', 'hr', 'pl', 'is', 'ja', 'ur'}\n"
     ]
    }
   ],
   "source": [
    "# Convert to set for faster look-up\n",
    "non_english_Langs = set(non_english_languages)\n",
    "\n",
    "# Get supported languages by Google Translate - we need the VALUES (codes) from the dictionary\n",
    "supported_languages_dict = GoogleTranslator().get_supported_languages(as_dict=True)\n",
    "print(\"Supported languages dictionary sample:\", dict(list(supported_languages_dict.items())[:10]))\n",
    "\n",
    "# Extract just the language CODES (the values)\n",
    "supported_language_codes = set(supported_languages_dict.values())\n",
    "print(f\"Supported language codes: {len(supported_language_codes)} languages\")\n",
    "\n",
    "# Also handle Chinese variants - map zh to zh-CN if needed\n",
    "if 'zh' in non_english_Langs and 'zh' not in supported_language_codes:\n",
    "    print(\"Note: 'zh' detected in dataset, will map to 'zh-CN' for translation\")\n",
    "    non_english_Langs.discard('zh')\n",
    "    non_english_Langs.add('zh-CN')\n",
    "\n",
    "# Find intersection between our dataset languages and supported language codes\n",
    "SUPPORTED_LANGS = non_english_Langs.intersection(supported_language_codes)\n",
    "\n",
    "print(f\"Non-English languages from dataset: {len(non_english_Langs)}\")\n",
    "print(f\"Supported languages for translation: {len(SUPPORTED_LANGS)}\")\n",
    "print(f\"Supported languages: {SUPPORTED_LANGS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09a6651",
   "metadata": {},
   "source": [
    " 43 out 47 non-English languages are supported by Google Translate. The 4 unsupported languages will be drooped during processing to maintain data quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e5d736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define translation function with chunk processing\n",
    "def translate_chunk(chunk):\n",
    "    \"\"\"Translate a chunk of data and return processed DataFrame\"\"\"\n",
    "    translated_data = []\n",
    "    \n",
    "    # Language mapping for Google Translate (for any remaining mismatches)\n",
    "    language_mapping = {\n",
    "        'zh': 'zh-CN',  # Chinese simplified\n",
    "        'he': 'iw',     # Hebrew  \n",
    "        'nb': 'no',     # Norwegian Bokmål\n",
    "    }\n",
    "    \n",
    "    for idx, row in chunk.iterrows():\n",
    "        try:\n",
    "            lang = row['language']\n",
    "            title = row['title']\n",
    "            \n",
    "            # Skip if title is NaN or empty\n",
    "            if pd.isna(title) or str(title).strip() == '':\n",
    "                continue\n",
    "                \n",
    "            # If language is English, use original as translated\n",
    "            if lang == 'en':\n",
    "                translated_title = str(title)\n",
    "            # If language is non-English BUT not supported, SKIP/DROP this row\n",
    "            elif lang not in SUPPORTED_LANGS:\n",
    "                continue  # This drops unsupported languages\n",
    "            else:\n",
    "                # Map language code if needed\n",
    "                source_lang = language_mapping.get(lang, lang)\n",
    "                \n",
    "                # Translate supported non-English languages\n",
    "                translated_title = GoogleTranslator(source=source_lang, target='en').translate(str(title))\n",
    "            \n",
    "            # Add to results (only English and successfully translated rows)\n",
    "            translated_data.append({\n",
    "                'language': lang,\n",
    "                'title': title,\n",
    "                'translated_title': translated_title\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Drop failed rows, continue without adding\n",
    "            continue\n",
    "    \n",
    "    return pd.DataFrame(translated_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca26d07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the entire dataset in chunks\n",
    "def process_dataset_in_chunks(input_df, chunk_size=1000):\n",
    "    \"\"\"Process the entire dataset in chunks and return combined DataFrame\"\"\"\n",
    "    \n",
    "    # Initialize counters and storage\n",
    "    total_processed = 0\n",
    "    total_successful = 0\n",
    "    chunks_processed = 0\n",
    "    all_translated_data = []\n",
    "    \n",
    "    # Calculate number of chunks\n",
    "    total_chunks = (len(input_df) // chunk_size) + 1\n",
    "    print(f\"Processing {len(input_df)} rows in {total_chunks} chunks of {chunk_size}...\")\n",
    "    \n",
    "    # Process in chunks\n",
    "    for chunk_num in range(total_chunks):\n",
    "        start_idx = chunk_num * chunk_size\n",
    "        end_idx = min((chunk_num + 1) * chunk_size, len(input_df))\n",
    "        chunk = input_df.iloc[start_idx:end_idx]\n",
    "        \n",
    "        print(f\"Processing chunk {chunk_num + 1}/{total_chunks} (rows {start_idx}-{end_idx})...\")\n",
    "        \n",
    "        # Translate chunk\n",
    "        translated_chunk = translate_chunk(chunk)\n",
    "        \n",
    "        # Update counters\n",
    "        chunk_successful = len(translated_chunk)\n",
    "        total_processed += len(chunk)\n",
    "        total_successful += chunk_successful\n",
    "        chunks_processed += 1\n",
    "        \n",
    "        # Store results\n",
    "        if not translated_chunk.empty:\n",
    "            all_translated_data.append(translated_chunk)\n",
    "            print(f\"  Chunk {chunk_num + 1}: {chunk_successful} successful, {len(chunk) - chunk_successful} failed\")\n",
    "        else:\n",
    "            print(f\"  Chunk {chunk_num + 1}: No successful translations\")\n",
    "        \n",
    "        # Rate limiting - be nice to the API\n",
    "        time.sleep(1)  # 1 second between chunks\n",
    "        if chunks_processed % 10 == 0:  # Longer break every 10 chunks\n",
    "            print(\"  Taking a longer break...\")\n",
    "            time.sleep(3)\n",
    "    \n",
    "    # Combine all chunks\n",
    "    if all_translated_data:\n",
    "        final_df = pd.concat(all_translated_data, ignore_index=True)\n",
    "    else:\n",
    "        final_df = pd.DataFrame(columns=['language', 'title', 'translated_title'])\n",
    "    \n",
    "    # Final summary\n",
    "    print(f\"\\nProcessing complete!\")\n",
    "    print(f\"Total rows processed: {total_processed}\")\n",
    "    print(f\"Total successful translations: {total_successful}\")\n",
    "    print(f\"Total failed/dropped: {total_processed - total_successful}\")\n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a6ab00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 35399 rows in 36 chunks of 1000...\n",
      "Processing chunk 1/36 (rows 0-1000)...\n",
      "  Chunk 1: 969 successful, 31 failed\n",
      "Processing chunk 2/36 (rows 1000-2000)...\n",
      "  Chunk 2: 993 successful, 7 failed\n",
      "Processing chunk 3/36 (rows 2000-3000)...\n",
      "  Chunk 3: 995 successful, 5 failed\n",
      "Processing chunk 4/36 (rows 3000-4000)...\n",
      "  Chunk 4: 989 successful, 11 failed\n",
      "Processing chunk 5/36 (rows 4000-5000)...\n",
      "  Chunk 5: 991 successful, 9 failed\n",
      "Processing chunk 6/36 (rows 5000-6000)...\n",
      "  Chunk 6: 996 successful, 4 failed\n",
      "Processing chunk 7/36 (rows 6000-7000)...\n",
      "  Chunk 7: 996 successful, 4 failed\n",
      "Processing chunk 8/36 (rows 7000-8000)...\n",
      "  Chunk 8: 999 successful, 1 failed\n",
      "Processing chunk 9/36 (rows 8000-9000)...\n",
      "  Chunk 9: 991 successful, 9 failed\n",
      "Processing chunk 10/36 (rows 9000-10000)...\n",
      "  Chunk 10: 994 successful, 6 failed\n",
      "  Taking a longer break...\n",
      "Processing chunk 11/36 (rows 10000-11000)...\n",
      "  Chunk 11: 999 successful, 1 failed\n",
      "Processing chunk 12/36 (rows 11000-12000)...\n",
      "  Chunk 12: 997 successful, 3 failed\n",
      "Processing chunk 13/36 (rows 12000-13000)...\n",
      "  Chunk 13: 993 successful, 7 failed\n",
      "Processing chunk 14/36 (rows 13000-14000)...\n",
      "  Chunk 14: 995 successful, 5 failed\n",
      "Processing chunk 15/36 (rows 14000-15000)...\n",
      "  Chunk 15: 990 successful, 10 failed\n",
      "Processing chunk 16/36 (rows 15000-16000)...\n",
      "  Chunk 16: 985 successful, 15 failed\n",
      "Processing chunk 17/36 (rows 16000-17000)...\n",
      "  Chunk 17: 982 successful, 18 failed\n",
      "Processing chunk 18/36 (rows 17000-18000)...\n",
      "  Chunk 18: 985 successful, 15 failed\n",
      "Processing chunk 19/36 (rows 18000-19000)...\n",
      "  Chunk 19: 996 successful, 4 failed\n",
      "Processing chunk 20/36 (rows 19000-20000)...\n",
      "  Chunk 20: 984 successful, 16 failed\n",
      "  Taking a longer break...\n",
      "Processing chunk 21/36 (rows 20000-21000)...\n",
      "  Chunk 21: 986 successful, 14 failed\n",
      "Processing chunk 22/36 (rows 21000-22000)...\n",
      "  Chunk 22: 993 successful, 7 failed\n",
      "Processing chunk 23/36 (rows 22000-23000)...\n",
      "  Chunk 23: 994 successful, 6 failed\n",
      "Processing chunk 24/36 (rows 23000-24000)...\n",
      "  Chunk 24: 986 successful, 14 failed\n",
      "Processing chunk 25/36 (rows 24000-25000)...\n",
      "  Chunk 25: 982 successful, 18 failed\n",
      "Processing chunk 26/36 (rows 25000-26000)...\n",
      "  Chunk 26: 995 successful, 5 failed\n",
      "Processing chunk 27/36 (rows 26000-27000)...\n",
      "  Chunk 27: 992 successful, 8 failed\n",
      "Processing chunk 28/36 (rows 27000-28000)...\n",
      "  Chunk 28: 996 successful, 4 failed\n",
      "Processing chunk 29/36 (rows 28000-29000)...\n",
      "  Chunk 29: 996 successful, 4 failed\n",
      "Processing chunk 30/36 (rows 29000-30000)...\n",
      "  Chunk 30: 991 successful, 9 failed\n",
      "  Taking a longer break...\n",
      "Processing chunk 31/36 (rows 30000-31000)...\n",
      "  Chunk 31: 989 successful, 11 failed\n",
      "Processing chunk 32/36 (rows 31000-32000)...\n",
      "  Chunk 32: 986 successful, 14 failed\n",
      "Processing chunk 33/36 (rows 32000-33000)...\n",
      "  Chunk 33: 986 successful, 14 failed\n",
      "Processing chunk 34/36 (rows 33000-34000)...\n",
      "  Chunk 34: 997 successful, 3 failed\n",
      "Processing chunk 35/36 (rows 34000-35000)...\n",
      "  Chunk 35: 996 successful, 4 failed\n",
      "Processing chunk 36/36 (rows 35000-35399)...\n",
      "  Chunk 36: 391 successful, 8 failed\n",
      "\n",
      "Processing complete!\n",
      "Total rows processed: 35399\n",
      "Total successful translations: 35075\n",
      "Total failed/dropped: 324\n"
     ]
    }
   ],
   "source": [
    "# Process the dataset in chunks\n",
    "translated_df = process_dataset_in_chunks(df, chunk_size=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb655e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "output_file = \"data/mediacloud-translated-complete.csv\"\n",
    "translated_df.to_csv(output_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0643b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "language",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "translated_title",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "4c564ac2-ada2-4d2b-b488-982bf0809aef",
       "rows": [
        [
         "0",
         "en",
         "Google pulls Gemma from AI Studio after Senator Blackburn accuses model of defamation",
         "Google pulls Gemma from AI Studio after Senator Blackburn accuses model of defamation"
        ],
        [
         "1",
         "en",
         "Here's why India’s AI content draft rules miss the mark on consumer protection",
         "Here's why India’s AI content draft rules miss the mark on consumer protection"
        ],
        [
         "2",
         "en",
         "Who is Zico Kolter? A professor leads OpenAI safety panel with power to halt unsafe AI releases",
         "Who is Zico Kolter? A professor leads OpenAI safety panel with power to halt unsafe AI releases"
        ],
        [
         "3",
         "es",
         "ChatGPT no es un psicólogo, pero cambiará su lenguaje para alertar a usuarios con problemas de salud mental",
         "ChatGPT is not a psychologist, but it will change its language to alert users with mental health problems"
        ],
        [
         "4",
         "en",
         "Like maple syrup and hockey, AI must become a part of our national identity",
         "Like maple syrup and hockey, AI must become a part of our national identity"
        ],
        [
         "5",
         "en",
         "The professor leading OpenAI's safety panel may have one of the most important roles in the tech industry right now",
         "The professor leading OpenAI's safety panel may have one of the most important roles in the tech industry right now"
        ],
        [
         "6",
         "en",
         "I spoke to Bill de Blasio about being cloned—and what public figures can do when AI fakes strike: 'All you can do is go online and deny what it is'",
         "I spoke to Bill de Blasio about being cloned—and what public figures can do when AI fakes strike: 'All you can do is go online and deny what it is'"
        ],
        [
         "7",
         "es",
         "Javier Esteban López, experto en inteligencia artificial: \"En el ámbito judicial, se están probando sistemas de IA que redactan borradores de resoluciones\"",
         "Javier Esteban López, expert in artificial intelligence: \"In the judicial field, AI systems that write draft resolutions are being tested\""
        ],
        [
         "8",
         "en",
         "Who is Zico Kolter? A professor leads OpenAI safety panel with power to halt unsafe AI releases",
         "Who is Zico Kolter? A professor leads OpenAI safety panel with power to halt unsafe AI releases"
        ],
        [
         "9",
         "en",
         "Who is Zico Kolter? A professor leads OpenAI safety panel with power to halt unsafe AI releases",
         "Who is Zico Kolter? A professor leads OpenAI safety panel with power to halt unsafe AI releases"
        ],
        [
         "10",
         "en",
         "New AI law to be modelled on IT Act",
         "New AI law to be modelled on IT Act"
        ],
        [
         "11",
         "en",
         "Buck Sexton Warns: “America’s Next Wealth Boom Has Already Begun”",
         "Buck Sexton Warns: “America’s Next Wealth Boom Has Already Begun”"
        ],
        [
         "12",
         "en",
         "Who is Zico Kolter? A professor leads OpenAI safety panel with power to halt unsafe AI releases",
         "Who is Zico Kolter? A professor leads OpenAI safety panel with power to halt unsafe AI releases"
        ],
        [
         "13",
         "en",
         "Listener's Day on RRI",
         "Listener's Day on RRI"
        ],
        [
         "14",
         "en",
         "Who is Zico Kolter? A professor leads OpenAI safety panel with power to halt unsafe AI releases",
         "Who is Zico Kolter? A professor leads OpenAI safety panel with power to halt unsafe AI releases"
        ],
        [
         "15",
         "ja",
         "リストラしちゃって大丈夫？ AI、意外と人間より仕事さばけない説",
         "Is it okay to restructure? AI is surprisingly incapable of handling tasks than humans"
        ],
        [
         "16",
         "en",
         "Asean’s summits and the security lens that fits them best — Phar Kim Beng",
         "Asean’s summits and the security lens that fits them best — Phar Kim Beng"
        ],
        [
         "17",
         "en",
         "Who is Zico Kolter? A professor leads OpenAI safety panel with power to halt unsafe AI releases",
         "Who is Zico Kolter? A professor leads OpenAI safety panel with power to halt unsafe AI releases"
        ],
        [
         "18",
         "en",
         "Politicians are increasingly pushing AI-generated content. It's scaring other politicians.",
         "Politicians are increasingly pushing AI-generated content. It's scaring other politicians."
        ],
        [
         "19",
         "es",
         "La IA toma Alicante con un foro de primer nivel internacional",
         "AI takes over Alicante with a top-level international forum"
        ],
        [
         "20",
         "en",
         "South Korea, Singapore agree to establish strategic partnership",
         "South Korea, Singapore agree to establish strategic partnership"
        ],
        [
         "21",
         "es",
         "La IA toma Alicante con un foro de primer nivel internacional",
         "AI takes over Alicante with a top-level international forum"
        ],
        [
         "22",
         "en",
         "Singapore and S. Korea launch strategic partnership to deepen economic links, defence cooperation",
         "Singapore and S. Korea launch strategic partnership to deepen economic links, defence cooperation"
        ],
        [
         "23",
         "en",
         "Singapore and S. Korea launch strategic partnership to deepen economic links, defence cooperation",
         "Singapore and S. Korea launch strategic partnership to deepen economic links, defence cooperation"
        ],
        [
         "24",
         "en",
         "Singapore and South Korea upgrade ties to Strategic Partnership, ink new deals on cultural exchange, shipping",
         "Singapore and South Korea upgrade ties to Strategic Partnership, ink new deals on cultural exchange, shipping"
        ],
        [
         "25",
         "es",
         "La IA, un punto de inflexión en las ciudades",
         "AI, a turning point in cities"
        ],
        [
         "26",
         "en",
         "Saturday 1st November 2025",
         "Saturday 1st November 2025"
        ],
        [
         "27",
         "es",
         "Coche autónomo: futuro o presente (casi) inmediato",
         "Autonomous car: future or (almost) immediate present"
        ],
        [
         "28",
         "en",
         "The Wolves And The Bees: AI Shows New Evolution",
         "The Wolves And The Bees: AI Shows New Evolution"
        ],
        [
         "29",
         "de",
         "âDurch den Kakao gezogenâ",
         "âDrenched through cocoaâ"
        ],
        [
         "30",
         "en",
         "Ahsan calls for empowering youth with digital, AI skills to build a smart, secure Pakistan",
         "Ahsan calls for empowering youth with digital, AI skills to build a smart, secure Pakistan"
        ],
        [
         "31",
         "en",
         "Saturday 1st November 2025",
         "Saturday 1st November 2025"
        ],
        [
         "32",
         "en",
         "AI’s Impacts and its governance: A Silicon Valley perspective",
         "AI’s Impacts and its governance: A Silicon Valley perspective"
        ],
        [
         "33",
         "en",
         "New CPRS Research challenges PR identity, urges AI readiness and calls for leadership on trust",
         "New CPRS Research challenges PR identity, urges AI readiness and calls for leadership on trust"
        ],
        [
         "34",
         "en",
         "Ahsan Iqbal calls for empowering youths with digital and AI skills to build a smart, secure Pakistan",
         "Ahsan Iqbal calls for empowering youths with digital and AI skills to build a smart, secure Pakistan"
        ],
        [
         "35",
         "en",
         "Shadow IT is threatening businesses from within",
         "Shadow IT is threatening businesses from within"
        ],
        [
         "36",
         "en",
         "Governments must invest more in preparing workers for AI, ‘cannot leave it to the market’: PM Wong",
         "Governments must invest more in preparing workers for AI, ‘cannot leave it to the market’: PM Wong"
        ],
        [
         "37",
         "en",
         "Apec members should keep cross-border data flowing to unlock value of AI: PM Wong",
         "Apec members should keep cross-border data flowing to unlock value of AI: PM Wong"
        ],
        [
         "38",
         "pl",
         "Sztuczna inteligencja dla wszystkich",
         "Artificial intelligence for everyone"
        ],
        [
         "39",
         "en",
         "Governments must invest more in preparing workers for AI, ‘cannot leave it to the market’: PM Wong",
         "Governments must invest more in preparing workers for AI, ‘cannot leave it to the market’: PM Wong"
        ],
        [
         "40",
         "en",
         "AI is making death threats way more realistic",
         "AI is making death threats way more realistic"
        ],
        [
         "41",
         "en",
         "Chainlink's LINK Drops 8% Below Support Despite Largest Token Buyback Since August",
         "Chainlink's LINK Drops 8% Below Support Despite Largest Token Buyback Since August"
        ],
        [
         "42",
         "en",
         "BNB Slips Below Support as Broader Crypto Market Reacts to Fed Chair's Remarks",
         "BNB Slips Below Support as Broader Crypto Market Reacts to Fed Chair's Remarks"
        ],
        [
         "43",
         "en",
         "New CPRS Research challenges PR identity, urges AI readiness and calls for leadership on trust",
         "New CPRS Research challenges PR identity, urges AI readiness and calls for leadership on trust"
        ],
        [
         "44",
         "en",
         "Analyst Says Ethereum Is the Best Ecosystem and Ether Is Poised to Top $5,000",
         "Analyst Says Ethereum Is the Best Ecosystem and Ether Is Poised to Top $5,000"
        ],
        [
         "45",
         "en",
         "Character.ai limits AI chat access for underage users",
         "Character.ai limits AI chat access for underage users"
        ],
        [
         "46",
         "en",
         "Character.AI to Block Minors from Using AI Chatbot 'Companions' as Safety Concerns Mount",
         "Character.AI to Block Minors from Using AI Chatbot 'Companions' as Safety Concerns Mount"
        ],
        [
         "47",
         "en",
         "This Racist Technology Is Already Upending People's Lives — And We Need To Prepare For The Worst",
         "This Racist Technology Is Already Upending People's Lives — And We Need To Prepare For The Worst"
        ],
        [
         "48",
         "ja",
         "Anthropic日本法人設立──「信頼性」を担保し「Claude Code」で開発を加速",
         "Establishment of Anthropic Japanese subsidiary ── Guaranteeing “reliability” and accelerating development with “Claude Code”"
        ],
        [
         "49",
         "en",
         "California regulation frenzy risks burgeoning AI industry",
         "California regulation frenzy risks burgeoning AI industry"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 35075
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>title</th>\n",
       "      <th>translated_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en</td>\n",
       "      <td>Google pulls Gemma from AI Studio after Senato...</td>\n",
       "      <td>Google pulls Gemma from AI Studio after Senato...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en</td>\n",
       "      <td>Here's why India’s AI content draft rules miss...</td>\n",
       "      <td>Here's why India’s AI content draft rules miss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en</td>\n",
       "      <td>Who is Zico Kolter? A professor leads OpenAI s...</td>\n",
       "      <td>Who is Zico Kolter? A professor leads OpenAI s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>es</td>\n",
       "      <td>ChatGPT no es un psicólogo, pero cambiará su l...</td>\n",
       "      <td>ChatGPT is not a psychologist, but it will cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en</td>\n",
       "      <td>Like maple syrup and hockey, AI must become a ...</td>\n",
       "      <td>Like maple syrup and hockey, AI must become a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35070</th>\n",
       "      <td>en</td>\n",
       "      <td>New Delhi Slush’D witnessed unprecedented succ...</td>\n",
       "      <td>New Delhi Slush’D witnessed unprecedented succ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35071</th>\n",
       "      <td>en</td>\n",
       "      <td>AI on human rights watch</td>\n",
       "      <td>AI on human rights watch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35072</th>\n",
       "      <td>es</td>\n",
       "      <td>Con su propia criptomoneda, el creador del Cha...</td>\n",
       "      <td>With his own cryptocurrency, the creator of Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35073</th>\n",
       "      <td>en</td>\n",
       "      <td>Musk ‘sensationalist’ comments on AI taking jo...</td>\n",
       "      <td>Musk ‘sensationalist’ comments on AI taking jo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35074</th>\n",
       "      <td>ru</td>\n",
       "      <td>Угроза катастрофического уровня: США и Китай п...</td>\n",
       "      <td>Catastrophic threat: US and China agree on AI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35075 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      language                                              title  \\\n",
       "0           en  Google pulls Gemma from AI Studio after Senato...   \n",
       "1           en  Here's why India’s AI content draft rules miss...   \n",
       "2           en  Who is Zico Kolter? A professor leads OpenAI s...   \n",
       "3           es  ChatGPT no es un psicólogo, pero cambiará su l...   \n",
       "4           en  Like maple syrup and hockey, AI must become a ...   \n",
       "...        ...                                                ...   \n",
       "35070       en  New Delhi Slush’D witnessed unprecedented succ...   \n",
       "35071       en                           AI on human rights watch   \n",
       "35072       es  Con su propia criptomoneda, el creador del Cha...   \n",
       "35073       en  Musk ‘sensationalist’ comments on AI taking jo...   \n",
       "35074       ru  Угроза катастрофического уровня: США и Китай п...   \n",
       "\n",
       "                                        translated_title  \n",
       "0      Google pulls Gemma from AI Studio after Senato...  \n",
       "1      Here's why India’s AI content draft rules miss...  \n",
       "2      Who is Zico Kolter? A professor leads OpenAI s...  \n",
       "3      ChatGPT is not a psychologist, but it will cha...  \n",
       "4      Like maple syrup and hockey, AI must become a ...  \n",
       "...                                                  ...  \n",
       "35070  New Delhi Slush’D witnessed unprecedented succ...  \n",
       "35071                           AI on human rights watch  \n",
       "35072  With his own cryptocurrency, the creator of Ch...  \n",
       "35073  Musk ‘sensationalist’ comments on AI taking jo...  \n",
       "35074      Catastrophic threat: US and China agree on AI  \n",
       "\n",
       "[35075 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
